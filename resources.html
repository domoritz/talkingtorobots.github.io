<!DOCTYPE html>
<html lang="en">
  <head>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM" crossorigin="anonymous"></script>
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <meta name=viewport content="width=device-width, initial-scale=1">


    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-GZ7BV93KNM"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-GZ7BV93KNM');
    </script>


    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="author" content:"Yonatan Bisk">
    <link rel="canonical" href="https://talkingtorobots.com">
    <title>Resources</title>
    <meta name="title" content="Resources">
    <meta name="description" content="Resources">

    <!-- Open Graph -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://talkingtorobots.com/resources.html">
    <meta property="og:title" content:"CLAW Resources">
    <meta property="og:image" content="https://talkingtorobots.com/teaching/images/cmu-logo.png">
    <meta property="og:description" content="Resources">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://talkingtorobots.com/resources.html">
    <meta property="twitter:title" content:"CLAW Resources">
    <meta property="twitter:image" content="https://talkingtorobots.com/teaching/images/cmu-logo.png">
    <meta property="twitter:description" content="Resources">

    <link rel="stylesheet" href="main.css">
    <link rel="icon" type="image/png" href="https://talkingtorobots.com/images/cmu-icon.png">
  </head>
  <body>

    <nav class="navbar navbar-expand-md">
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbars" aria-controls="navbars" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>

      <div class="collapse navbar-collapse" id="navbars">
        <div class="navbar-nav nav-fill w-100">
          <a class="nav-item nav-link" href="publications.html" >Publications</a>
          <a class="nav-item nav-link" href="CLAW/" >Group</a>
          <a class="nav-item nav-link" href="index.html">
            <img alt="image of a robot claw" height=40px 
                 src="images/CLAW.svg" 
                 onmouseover="this.src='images/CLAW-animated.svg';"
                 onmouseout="this.src='images/CLAW.svg';"
                style="padding: 2px;filter: invert(1);">
          </a>
          <a class="nav-item nav-link" href="teaching.html" >Teaching</a>
          <a class="nav-item nav-link active" href="#" ><span class="visually-hidden">(current)</span>Resources</a>
        </div>
      </div>
    </nav>

    <div class="wrapper" >
      <div class="content">
        <center><h3><b>C</b>onnecting <b>L</b>anguage to <b>A</b>ctions & the <b>W</b>orld @ CMU</h3></center>
      </div>
    </div>

    <br><br>
    <center>
      <table class="table table-hover table-condensed table-striped" style="max-width:800px">
        <thead>
          <tr class="d-flex" style="border-top:none;">
            <th class="col-sm-4" style="border-top:none;"><h4>Project</h4></td>
            <th class="col-sm-8" style="border-top:none;"><h4>Description</h4></td>
          </tr>
        </thead>
        <tr class="d-flex" style="border-top:none;">
          <td class="col-sm-4" style="border-top:none;"><h4><a href="https://ovmm.github.io/">Open-Vocabulary Mobile Manipulation</a></h4></td>
          <td class="col-sm-8" style="border-top:none;">Open-Vocabulary Mobile Manipulation (OVMM) is the problem of picking any object in any unseen environment, and placing it in a commanded location.  The benchmark includes both simulation environments and parallel stack for robot control.</td>
        </tr>
        <tr class="d-flex" style="border-top:none;">
          <td class="col-sm-4" style="border-top:none;"><h4><a href="https://webqna.github.io/">WebQA Benchmark</a></h4></td>
          <td class="col-sm-8" style="border-top:none;">WebQA, is a new benchmark for multimodal multihop reasoning in which systems are presented with the same style of data as humans when searching the web: Snippets and Images. The system must then identify which information is relevant across modalities and combine it with reasoning to answer the query. Systems will be evaluated on both the correctness of their answers and their sources.</td>
        </tr>
        <tr class="d-flex" style="border-top:none;">
          <td class="col-sm-4" style="border-top:none;"><h4><a href="https://github.com/guilk/VLC">VLC Checkpoints</a></h4></td>
          <td class="col-sm-8" style="border-top:none;">Training Vision-language Transformers from Captions Alone.  An MAE based Vision-Language Transformer that doesn't rely on supervised class labels.</td>
        </tr>
        <tr class="d-flex" style="border-top:none;">
          <td class="col-sm-4" style="border-top:none;"><h4><a href="https://askforalfred.com/">ALFRED</a> & <br><a href="https://soyeonm.github.io/FILM_webpage/">FILM Code</a></h4></td>
          <td class="col-sm-8" style="border-top:none;">ALFRED (Action Learning From Realistic Environments and Directives), is a new benchmark for learning a mapping from natural language instructions and egocentric vision to sequences of actions for household tasks. Long composition rollouts with non-reversible state changes are among the phenomena we include to shrink the gap between research benchmarks and real-world applications.<br>
            </td>
        </tr>
      </table>
      <br><br>
    </center>
  </body>
</html>


